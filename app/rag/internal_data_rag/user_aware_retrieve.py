# app/rag/internal_data_rag/user_aware_retrieve.py
# -*- coding: utf-8 -*-
"""
ì‚¬ìš©ìë³„ ê¶Œí•œì„ ê³ ë ¤í•œ RAG ë¬¸ì„œ ê²€ìƒ‰ ì„œë¹„ìŠ¤
- íšŒì‚¬ ê³µê°œ ë¬¸ì„œ: ê°™ì€ íšŒì‚¬ ì§ì› ëª¨ë‘ ì ‘ê·¼ ê°€ëŠ¥
- ê°œì¸ ë¬¸ì„œ: ë³¸ì¸ë§Œ ì ‘ê·¼ ê°€ëŠ¥
- ë‹¤ë¥¸ ì§ì›ì˜ ê°œì¸ ë¬¸ì„œ: ì ‘ê·¼ ë¶ˆê°€
"""

import os
from typing import List, Tuple, Optional
from sqlalchemy.orm import Session

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.tools import tool
from langchain_core.documents import Document

from app.utils.db import get_db
from app.features.login.employee_google import crud as employee_crud
from app.features.admin.services.file_ingest_service import _get_company_code
from app.rag.internal_data_rag.internal_retrieve import (
    _stable_similarity,
    _truncate_context_blocks,
    MAX_CONTEXT_CHARS,
    CHROMA_PATH,
    EMBED_MODEL,
    CHAT_MODEL,
)


class UserAwareRAGService:
    """ì‚¬ìš©ìë³„ ê¶Œí•œì„ ê³ ë ¤í•œ RAG ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(model=EMBED_MODEL)
        self.llm = ChatOpenAI(model=CHAT_MODEL, temperature=0)
        self.parser = StrOutputParser()
        self.prompt = ChatPromptTemplate.from_messages([
            (
                "system",
                "ë‹¹ì‹ ì€ ì‚¬ë‚´ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ ë‹µí•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
                "ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì—ì„œë§Œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë‹µë³€í•˜ê³ , "
                "ì¶”ì¸¡í•˜ì§€ ë§ê³  ëª¨ë¥´ëŠ” ë‚´ìš©ì€ 'ëª¨ë¥¸ë‹¤'ê³  ëª…í™•íˆ ë§í•˜ì„¸ìš”. "
                "ê°€ëŠ¥í•œ í•œ ì¶œì²˜ ë¬¸ì„œëª…ê³¼ í•¨ê»˜ ë‹µë³€í•˜ì„¸ìš”.",
            ),
            (
                "user",
                "ì§ˆë¬¸: {question}\n\n"
                "ì°¸ê³  ì»¨í…ìŠ¤íŠ¸(ì—¬ëŸ¬ ì²­í¬):\n{context}",
            ),
        ])

    def get_user_context(self, user_id: str) -> Optional[dict]:
        """
        user_id(google_user_id)ë¡œë¶€í„° ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
        Returns: {"employee_id": int, "company_id": int, "company_code": str} or None
        """
        try:
            db = next(get_db())
            employee = employee_crud.get_employee_by_google_id(db, google_user_id=user_id)
            if not employee:
                print(f"âŒ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_id}")
                return None
            
            company_code = _get_company_code(db, employee.company_id)
            return {
                "employee_id": employee.id,
                "company_id": employee.company_id,
                "company_code": company_code,
            }
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
        finally:
            db.close()

    def retrieve_documents_with_permission(
        self, 
        query: str, 
        user_id: str, 
        top_k: int = 5
    ) -> List[Tuple[str, dict]]:
        """
        ì‚¬ìš©ìë³„ ê¶Œí•œì„ ê³ ë ¤í•œ ë¬¸ì„œ ê²€ìƒ‰
        - íšŒì‚¬ ê³µê°œ ë¬¸ì„œ(is_private=False): ê°™ì€ íšŒì‚¬ ì§ì› ëª¨ë‘ ì ‘ê·¼ ê°€ëŠ¥
        - ê°œì¸ ë¬¸ì„œ(is_private=True): ë³¸ì¸(user_id)ë§Œ ì ‘ê·¼ ê°€ëŠ¥
        """
        user_context = self.get_user_context(user_id)
        if not user_context:
            print(f"âŒ ì‚¬ìš©ì ì •ë³´ ì—†ìŒ - ê²€ìƒ‰ ì¤‘ë‹¨: {user_id}")
            return []
        
        company_code = user_context["company_code"]
        employee_id = user_context["employee_id"]
        
        try:
            print(f"ğŸ” ê¶Œí•œë³„ ë¬¸ì„œ ê²€ìƒ‰: '{query}' (íšŒì‚¬: {company_code}, ì‚¬ìš©ì: {employee_id})")
            
            # íšŒì‚¬ë³„ ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰
            vectorstore = Chroma(
                collection_name=company_code,
                embedding_function=self.embeddings,
                persist_directory=CHROMA_PATH,
            )
            
            # ë” ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ ê¶Œí•œ í•„í„°ë§ í›„ top_k ë§Œí¼ ë°˜í™˜
            results = vectorstore.similarity_search_with_score(query, k=top_k * 2)
            
            if not results:
                print("âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return []

            # ê¶Œí•œ í•„í„°ë§
            filtered_contexts = []
            for doc, distance in results:
                meta = dict(doc.metadata or {})
                is_private = meta.get("is_private", False)
                doc_user_id = meta.get("user_id")  # ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•œ ì‚¬ìš©ì ID (employee_id)
                doc_company_id = meta.get("company_id")  # ë¬¸ì„œê°€ ì†í•œ íšŒì‚¬ ID
                
                # ê¶Œí•œ ì²´í¬
                # 1. íšŒì‚¬ ê²€ì¦: ë¬¸ì„œì˜ company_idì™€ í˜„ì¬ ì‚¬ìš©ìì˜ company_idê°€ ê°™ì•„ì•¼ í•¨
                if doc_company_id != user_context["company_id"]:
                    print(f"ğŸ”’ ë‹¤ë¥¸ íšŒì‚¬ ë¬¸ì„œ ì ‘ê·¼ ì°¨ë‹¨: doc_company={doc_company_id}, user_company={user_context['company_id']}")
                    continue
                
                # 2. ê°œì¸ ë¬¸ì„œ ê²€ì¦: is_private=Trueì¸ ê²½ìš° ë³¸ì¸ë§Œ ì ‘ê·¼ ê°€ëŠ¥
                if is_private:
                    if doc_user_id != employee_id:
                        print(f"ğŸ”’ ê°œì¸ ë¬¸ì„œ ì ‘ê·¼ ì°¨ë‹¨: doc_user_id={doc_user_id}, current_user={employee_id}")
                        continue
                # else: íšŒì‚¬ ê³µê°œ ë¬¸ì„œ(is_private=False) - ê°™ì€ íšŒì‚¬ë©´ ì ‘ê·¼ ê°€ëŠ¥
                
                similarity = _stable_similarity(distance)
                meta["similarity_score"] = similarity
                
                preview = (doc.page_content[:80] + "...") if len(doc.page_content) > 80 else doc.page_content
                print(f"  âœ… [í—ˆìš©] ìœ ì‚¬ë„={similarity:.4f}, private={is_private}, source={meta.get('source')}")
                print(f"          ë‚´ìš©: {preview}")
                
                filtered_contexts.append((doc.page_content, meta))
                
                # top_k ê°œìˆ˜ë§Œí¼ë§Œ ë°˜í™˜
                if len(filtered_contexts) >= top_k:
                    break
            
            print(f"âœ… ê¶Œí•œ í•„í„°ë§ í›„ {len(filtered_contexts)}ê°œ ë¬¸ì„œ ë°˜í™˜")
            return filtered_contexts
            
        except Exception as e:
            print(f"âŒ ê¶Œí•œë³„ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

    def generate_answer(
        self, query: str, contexts: List[Tuple[str, dict]], model: str = None
    ) -> str:
        """í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ë¥¼ ì£¼ì…í•´ LLM í˜¸ì¶œ"""
        if not contexts:
            return "ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”."

        try:
            model_label = model or CHAT_MODEL
            print(f"âš™ï¸ ë‹µë³€ ìƒì„± ì¤‘... ({len(contexts)}ê°œ ì»¨í…ìŠ¤íŠ¸, ëª¨ë¸: {model_label})")

            # ì»¨í…ìŠ¤íŠ¸ íŠ¸ë ì¼€ì´ì…˜ (ìœ ì‚¬ë„ ìˆœ)
            context_text = _truncate_context_blocks(contexts, max_chars=MAX_CONTEXT_CHARS)

            # LCEL ì²´ì¸ ì‹¤í–‰
            used_llm = self.llm if model is None else ChatOpenAI(model=model, temperature=0)
            chain = self.prompt | used_llm | self.parser
            answer = chain.invoke({"question": query, "context": context_text})

            print("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
            return answer
        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def query_rag_with_permission(
        self, 
        query: str, 
        user_id: str, 
        top_k: int = 4, 
        model: str = None, 
        show_sources: bool = True
    ) -> str:
        """ì‚¬ìš©ìë³„ ê¶Œí•œì„ ê³ ë ¤í•œ RAG ì§ˆì˜ ì²˜ë¦¬"""
        print(f"\nğŸ” ê¶Œí•œë³„ RAG ì§ˆì˜: {query} (ì‚¬ìš©ì: {user_id})")

        contexts = self.retrieve_documents_with_permission(query, user_id, top_k)
        if not contexts:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì ‘ê·¼ ê°€ëŠ¥í•œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        answer = self.generate_answer(query, contexts, model)

        if show_sources:
            sources = []
            for _, meta in contexts:
                is_private = meta.get("is_private", False)
                doc_type = "ê°œì¸ ë¬¸ì„œ" if is_private else "íšŒì‚¬ ë¬¸ì„œ"
                src = f"- {meta.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')} ({doc_type}, ì²­í¬ {meta.get('chunk_idx', 'N/A')})"
                if src not in sources:
                    sources.append(src)
            return f"{answer}\n\nğŸ“‹ ì°¸ê³ í•œ ë¬¸ì„œ:\n" + "\n".join(sources)

        return answer


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
_user_aware_rag_service = UserAwareRAGService()


# ========================= LangChain ë„êµ¬ ì •ì˜ =========================

@tool
def user_aware_rag_search(query: str, user_id: str) -> str:
    """
    ì‚¬ìš©ìë³„ ê¶Œí•œì„ ê³ ë ¤í•œ ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰ ë„êµ¬
    - íšŒì‚¬ ê³µê°œ ë¬¸ì„œ: ê°™ì€ íšŒì‚¬ ì§ì› ëª¨ë‘ ì ‘ê·¼ ê°€ëŠ¥
    - ê°œì¸ ë¬¸ì„œ: ë³¸ì¸ë§Œ ì ‘ê·¼ ê°€ëŠ¥
    
    Args:
        query (str): ê²€ìƒ‰í•  ì§ˆë¬¸
        user_id (str): ì‚¬ìš©ì ID (Google User ID)
    
    Returns:
        str: ê²€ìƒ‰ ê²°ê³¼ ë° ë‹µë³€
    """
    try:
        return _user_aware_rag_service.query_rag_with_permission(
            query=query, 
            user_id=user_id, 
            top_k=4, 
            show_sources=True
        )
    except Exception as e:
        print(f"âŒ ì‚¬ìš©ìë³„ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# ========================= ì‚¬ìš©ìë³„ ë„êµ¬ íŒ©í† ë¦¬ =========================

def create_user_aware_rag_tools(user_id: str) -> list:
    """
    íŠ¹ì • ì‚¬ìš©ìë¥¼ ìœ„í•œ RAG ë„êµ¬ ìƒì„± (user_id ë°”ì¸ë”©)
    
    Args:
        user_id (str): ì‚¬ìš©ì ID (Google User ID)
    
    Returns:
        list: ì‚¬ìš©ìë³„ë¡œ ë°”ì¸ë”©ëœ RAG ë„êµ¬ ëª©ë¡
    """
    @tool
    def internal_rag_search(query: str) -> str:
        """
        ì‚¬ìš©ìë³„ ê¶Œí•œì„ ê³ ë ¤í•œ ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰
        - íšŒì‚¬ ê³µê°œ ë¬¸ì„œ: ê°™ì€ íšŒì‚¬ ì§ì› ëª¨ë‘ ì ‘ê·¼ ê°€ëŠ¥  
        - ê°œì¸ ë¬¸ì„œ: ë³¸ì¸ë§Œ ì ‘ê·¼ ê°€ëŠ¥
        """
        return _user_aware_rag_service.query_rag_with_permission(
            query=query, 
            user_id=user_id,  # íŒ©í† ë¦¬ì—ì„œ ì „ë‹¬ë°›ì€ user_id ë°”ì¸ë”©
            top_k=4,
            show_sources=True
        )
    
    return [internal_rag_search]


# ê¸°ì¡´ ë²”ìš© ë„êµ¬ (ë§¤ê°œë³€ìˆ˜ 2ê°œ - ì§ì ‘ í˜¸ì¶œìš©)
user_aware_rag_tools = [user_aware_rag_search]
